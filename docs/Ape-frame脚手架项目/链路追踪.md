# 链路追踪

> **手写链路追踪**（日志中携带traceId）
>
> **说明**：我们已经实现了记录操作和入参出参的Aop切面了，但是我们在查看日志的时候，可能会发现很多操作日志混乱的混在一起（被两个服务同时调用或者被多个服务调用，日志层面查看无法区分是谁调用的），导致我们无从排查相关信息或错误；
>
> **思考**：要是同一次的调用链路上的日志都加上同一个UUID或者唯一ID即可，这样那几条日志属于同一次调用就一目了然了！

## 开启日志输出的**PFTID**（profile trace id）

首先，我们有设置好的log4j-spring.xml的设置如下

其中主要是在日志中加入 MDC 的变量，我们这里取为 **PFTID**（profile trace id）

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!--Configuration后面的status，这个用于设置log4j2自身内部的信息输出，可以不设置，当设置成trace时，你会看到log4j2内部各种详细输出-->
<!--monitorInterval：Log4j能够自动检测修改配置 文件和重新配置本身，设置间隔秒数-->
<configuration status="INFO" monitorInterval="5">
    <!--日志级别以及优先级排序: OFF > FATAL > ERROR > WARN > INFO > DEBUG > TRACE > ALL -->
    <!--变量配置-->
    <Properties>
        <!-- 格式化输出：%date表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %msg：日志消息，%n是换行符-->
        <!-- %logger{36} 表示 Logger 名字最长36个字符 -->
        <property name="LOG_PATTERN" value="%date{HH:mm:ss.SSS} %X{PFTID} [%thread] %-5level %logger{36} - %msg%n"/> // [!code focus]
        <!-- 定义日志存储的路径 -->
        <property name="FILE_PATH" value="../log"/>
        <property name="FILE_NAME" value="frame.log"/>
    </Properties>

    <!--https://logging.apache.org/log4j/2.x/manual/appenders.html-->
    <appenders>

        <console name="Console" target="SYSTEM_OUT">
            <!--输出日志的格式-->
            <PatternLayout pattern="${LOG_PATTERN}"/>
            <!--控制台只输出level及其以上级别的信息（onMatch），其他的直接拒绝（onMismatch）-->
            <ThresholdFilter level="info" onMatch="ACCEPT" onMismatch="DENY"/>
        </console>

        <!--文件会打印出所有信息，这个log每次运行程序会自动清空，由append属性决定，适合临时测试用-->
        <File name="fileLog" fileName="${FILE_PATH}/temp.log" append="false">
            <PatternLayout pattern="${LOG_PATTERN}"/>
        </File>

        <!-- 这个会打印出所有的info及以下级别的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档-->
        <RollingFile name="RollingFileInfo" fileName="${FILE_PATH}/info.log"
                     filePattern="${FILE_PATH}/${FILE_NAME}-INFO-%d{yyyy-MM-dd}_%i.log.gz">
            <!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）-->
            <ThresholdFilter level="info" onMatch="ACCEPT" onMismatch="DENY"/>
            <PatternLayout pattern="${LOG_PATTERN}"/>
            <Policies>
                <!--interval属性用来指定多久滚动一次，默认是1 hour-->
                <TimeBasedTriggeringPolicy interval="1"/>
                <SizeBasedTriggeringPolicy size="10MB"/>
            </Policies>
            <!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖-->
            <DefaultRolloverStrategy max="15"/>
        </RollingFile>

        <!-- 这个会打印出所有的warn及以下级别的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档-->
        <RollingFile name="RollingFileWarn" fileName="${FILE_PATH}/warn.log"
                     filePattern="${FILE_PATH}/${FILE_NAME}-WARN-%d{yyyy-MM-dd}_%i.log.gz">
            <!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）-->
            <ThresholdFilter level="warn" onMatch="ACCEPT" onMismatch="DENY"/>
            <PatternLayout pattern="${LOG_PATTERN}"/>
            <Policies>
                <!--interval属性用来指定多久滚动一次，默认是1 hour-->
                <TimeBasedTriggeringPolicy interval="1"/>
                <SizeBasedTriggeringPolicy size="10MB"/>
            </Policies>
            <!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖-->
            <DefaultRolloverStrategy max="15"/>
        </RollingFile>

        <!-- 这个会打印出所有的error及以下级别的信息，每次大小超过size，则这size大小的日志会自动存入按年份-月份建立的文件夹下面并进行压缩，作为存档-->
        <RollingFile name="RollingFileError" fileName="${FILE_PATH}/error.log"
                     filePattern="${FILE_PATH}/${FILE_NAME}-ERROR-%d{yyyy-MM-dd}_%i.log.gz">
            <!--控制台只输出level及以上级别的信息（onMatch），其他的直接拒绝（onMismatch）-->
            <ThresholdFilter level="error" onMatch="ACCEPT" onMismatch="DENY"/>
            <PatternLayout pattern="${LOG_PATTERN}"/>
            <Policies>
                <!--interval属性用来指定多久滚动一次，默认是1 hour-->
                <TimeBasedTriggeringPolicy interval="1"/>
                <SizeBasedTriggeringPolicy size="10MB"/>
            </Policies>
            <!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件开始覆盖-->
            <DefaultRolloverStrategy max="15"/>
        </RollingFile>

    </appenders>

    <!--Logger节点用来单独指定日志的形式，比如要为指定包下的class指定不同的日志级别等。-->
    <!--然后定义loggers，只有定义了logger并引入的appender，appender才会生效-->
    <loggers>

        <!--过滤掉spring和mybatis的一些无用的DEBUG信息-->
        <logger name="org.mybatis" level="info" additivity="false">
            <AppenderRef ref="Console"/>
        </logger>
        <!--监控系统信息-->
        <!--若是additivity设为false，则子Logger只会在自己的appender里输出，而不会在父Logger的appender里输出。-->
        <Logger name="org.springframework" level="info" additivity="false">
            <AppenderRef ref="Console"/>
        </Logger>

        <AsyncLogger name="asyncLog" level="info" additivity="true">
            <appender-ref ref="RollingFileInfo"/>
        </AsyncLogger>

        <AsyncRoot level="info" includeLocation="true">
            <AppenderRef ref="RollingFileInfo"/>
        </AsyncRoot>

        <!--<root level="info">-->
        <!--    <appender-ref ref="Console"/>-->
        <!--    <appender-ref ref="RollingFileInfo"/>-->
        <!--    <appender-ref ref="RollingFileWarn"/>-->
        <!--    <appender-ref ref="RollingFileError"/>-->
        <!--    <appender-ref ref="fileLog"/>-->
        <!--</root>-->
    </loggers>

</configuration>
```

## 做一个过滤器的核心配置

```java
/**
 * 为了实现链路追踪
 * Filter过滤器配置
 */
@Configuration
public class FilterConfig {

    /**
    * 下方自定义
    */
    @Resource
    private TraceIdFilter traceIdFilter;

    @Bean
    public FilterRegistrationBean registrationFilter() {
        FilterRegistrationBean registrationBean = new FilterRegistrationBean();
        // 需要加入 traceId 的Filter
        registrationBean.setFilter(traceIdFilter);
        // 设置需要拦截的url, 所以所有请求都会被拦截
        registrationBean.addUrlPatterns("/*");
        // 设置名称
        registrationBean.setName("traceIdFilter");
        // 设置级别（越小越好）
        registrationBean.setOrder(1);
        return registrationBean;
    }
}
```

## 主要步骤

### **先搞一个TraceId的常量类TraceIdConstant**

```java
/**
 * TraceId常量
 */
public class TraceIdConstant {
    public static final String TRACE_ID = "PFTID";
}
```

### **存取TraceID的上下文：TraceIdContext**

```java
/**
 * TraceId上下文
 */
public class TraceIdContext {

    public static final ThreadLocal<String> CURRENT_TRACE_ID = new InheritableThreadLocal<>();

    public static String generateTraceId() {
        return UUID.randomUUID().toString();
    }

    public static String getTraceId() {
        return MDC.get(TraceIdConstant.TRACE_ID);
    }

    public static void setTraceId(String traceId) {
        MDC.put(TraceIdConstant.TRACE_ID, traceId);
    }

    public static void clearTraceId() {
        CURRENT_TRACE_ID.set(null);
        CURRENT_TRACE_ID.remove();
    }
}
```

### **接着是核心，过滤器TraceIdFilter**

```java
@Component
@Slf4j
@ConditionalOnProperty(name = {"traceId.filter.enable"}, havingValue = "true")
public class TraceIdFilter implements Filter {

    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        HttpServletRequest httpServletRequest = (HttpServletRequest) servletRequest;
        String traceId = httpServletRequest.getHeader(TraceIdConstant.TRACE_ID);
        // 如果TraceId为空，则赋值(可能多微服务调用，会从上游Http中获取)
        if (StringUtils.isBlank(traceId)) {
            // 生成TraceId
            traceId = TraceIdContext.generateTraceId();
        }
        // 将TraceId设置进MDC
        TraceIdContext.setTraceId(traceId);
        filterChain.doFilter(servletRequest, servletResponse);
        // 清空当前线程的TraceId
        TraceIdContext.clearTraceId();
    }
}
```

### 可以选择开启配置文件

```yaml
traceId:
  filter:
    enable: true
```

##运行结果

![img](https://york-blog-1327009977.cos.ap-nanjing.myqcloud.com//APE-FRAME%E8%84%9A%E6%89%8B%E6%9E%B6%E9%A1%B9%E7%9B%AE/1693728138291-d1e24c3c-9539-49ce-a392-d3c6fb0551b4.png)

**结论**：可以看到，在一条请求链路上的日志，其日志前面都附带有自己的uuid，这样我们就能根据这个uuid来区分哪些日志属于同一条请求链路了，也就实现了链路追踪功能！